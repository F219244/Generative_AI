{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s73QQ_sL5Qas"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "import random\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Roman-Urdu-Poetry (1).csv\")  # Use the correct file name\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Normalize Unicode characters (removes accents and diacritics)\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
        "\n",
        "    # Remove unwanted characters except for basic punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.,?!]\", \"\", text)\n",
        "\n",
        "    # Remove dots within words (fix ja.ega -> jaega, ro.ega -> roega)\n",
        "    text = re.sub(r\"\\.(?=\\w)\", \"\", text)\n",
        "\n",
        "    # Replace multiple spaces and newlines with a single space\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to poetry column\n",
        "df[\"Poetry\"] = df[\"Poetry\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "MuidaYiU-n9D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Poetry'])\n",
        "sequences = tokenizer.texts_to_sequences(df['Poetry'])\n",
        "max_sequence_length = 20\n",
        "\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, min(len(seq), max_sequence_length)):\n",
        "        input_sequences.append(seq[:i+1])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "BzGoawWv-0ej"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "        Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length-1),\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),\n",
        "        LSTM(128),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "    ])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8NlNpN4O-7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef023c9-4190-4e44-f24b-4e2699501ce7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, verbose=1)\n",
        "model.save(\"poetry_model.h5\")"
      ],
      "metadata": {
        "id": "XEXeGZlH-64r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f0cc5c-e98b-4389-ba79-e6eea2e0682e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.0413 - loss: 7.4907\n",
            "Epoch 2/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.0470 - loss: 6.5199\n",
            "Epoch 3/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.0446 - loss: 6.3236\n",
            "Epoch 4/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.0503 - loss: 6.1842\n",
            "Epoch 5/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.0645 - loss: 6.0331\n",
            "Epoch 6/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.0674 - loss: 5.9317\n",
            "Epoch 7/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.0763 - loss: 5.8390\n",
            "Epoch 8/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.0842 - loss: 5.7550\n",
            "Epoch 9/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.0898 - loss: 5.6582\n",
            "Epoch 10/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.0983 - loss: 5.5295\n",
            "Epoch 11/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1057 - loss: 5.4045\n",
            "Epoch 12/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.1111 - loss: 5.2765\n",
            "Epoch 13/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.1193 - loss: 5.1535\n",
            "Epoch 14/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1244 - loss: 5.0749\n",
            "Epoch 15/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1296 - loss: 4.9557\n",
            "Epoch 16/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.1412 - loss: 4.8085\n",
            "Epoch 17/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1470 - loss: 4.7131\n",
            "Epoch 18/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.1574 - loss: 4.6032\n",
            "Epoch 19/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1712 - loss: 4.4451\n",
            "Epoch 20/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.1757 - loss: 4.3565\n",
            "Epoch 21/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1889 - loss: 4.2241\n",
            "Epoch 22/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2056 - loss: 4.0814\n",
            "Epoch 23/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2159 - loss: 3.9823\n",
            "Epoch 24/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2284 - loss: 3.8598\n",
            "Epoch 25/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.2458 - loss: 3.7335\n",
            "Epoch 26/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.2588 - loss: 3.6337\n",
            "Epoch 27/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.2664 - loss: 3.5376\n",
            "Epoch 28/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.2827 - loss: 3.4140\n",
            "Epoch 29/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.3003 - loss: 3.3129\n",
            "Epoch 30/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.3178 - loss: 3.2061\n",
            "Epoch 31/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.3413 - loss: 3.0710\n",
            "Epoch 32/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.3585 - loss: 2.9606\n",
            "Epoch 33/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.3743 - loss: 2.8879\n",
            "Epoch 34/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.3861 - loss: 2.7895\n",
            "Epoch 35/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.4124 - loss: 2.6780\n",
            "Epoch 36/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.4279 - loss: 2.5807\n",
            "Epoch 37/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.4405 - loss: 2.5280\n",
            "Epoch 38/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.4622 - loss: 2.4011\n",
            "Epoch 39/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.4750 - loss: 2.3491\n",
            "Epoch 40/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.4828 - loss: 2.3082\n",
            "Epoch 41/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.4988 - loss: 2.2025\n",
            "Epoch 42/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.5165 - loss: 2.1290\n",
            "Epoch 43/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.5234 - loss: 2.0809\n",
            "Epoch 44/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.5427 - loss: 2.0179\n",
            "Epoch 45/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.5504 - loss: 1.9520\n",
            "Epoch 46/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.5658 - loss: 1.8992\n",
            "Epoch 47/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.5734 - loss: 1.8445\n",
            "Epoch 48/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.5942 - loss: 1.7537\n",
            "Epoch 49/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.6058 - loss: 1.7079\n",
            "Epoch 50/50\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.6169 - loss: 1.6459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "id": "ABOrbQ2OEnd2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poem(prompt, num_lines, words_per_line, temperature):\n",
        "    poem = []\n",
        "    current_word = prompt.lower()\n",
        "\n",
        "    for _ in range(num_lines):\n",
        "        line = current_word  # Start each line with the prompt word\n",
        "\n",
        "        for _ in range(words_per_line - 1):\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "\n",
        "            predictions = model.predict(token_list, verbose=0)[0]\n",
        "            predictions = np.log(predictions + 1e-10) / temperature\n",
        "            exp_preds = np.exp(predictions)\n",
        "            predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "            sorted_indices = np.argsort(predictions)[-5:]  # Top 5 words\n",
        "            possible_words = [tokenizer.index_word.get(idx, None) for idx in sorted_indices if idx in tokenizer.index_word]\n",
        "            possible_words = [word for word in possible_words if word is not None]\n",
        "\n",
        "            if possible_words:\n",
        "                word = random.choices(possible_words, weights=predictions[sorted_indices])[0]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "            line += \" \" + word\n",
        "            current_word = word\n",
        "\n",
        "        poem.append(line.capitalize())\n",
        "\n",
        "    return \"\\n\".join(poem)\n"
      ],
      "metadata": {
        "id": "ncKOKAg7-6dF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for the poem\n",
        "prompt = input(\"Enter text : \")\n",
        "lines = int(input(\"Enter number of lines : \"))\n",
        "words = int(input(\"Enter number of words per line : \"))\n",
        "temperature = float(input(\"Enter temperature : \"))\n",
        "# Generate the poem\n",
        "generated_poem = generate_poem(prompt,lines,words,temperature)\n",
        "print(\"\\nGenerated Poem:\\n\")\n",
        "print(generated_poem)\n"
      ],
      "metadata": {
        "id": "QTjCdPCk7WzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf8dacc-9e4a-477a-abce-a765936ef126"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text : pyaar\n",
            "Enter number of lines : 6\n",
            "Enter number of words per line : 6\n",
            "Enter temperature : 0.8\n",
            "\n",
            "Generated Poem:\n",
            "\n",
            "Pyaar kar kharab karo khvab ghazab\n",
            "Ghazab mil kar rahe ke honton\n",
            "Honton pe dekha akhir dil kuchh\n",
            "Kuchh faisla hi ho ya bahut\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kzjiKTjGDQN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}